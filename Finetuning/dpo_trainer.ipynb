{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-11T22:46:11.020819Z","iopub.status.busy":"2024-04-11T22:46:11.020465Z","iopub.status.idle":"2024-04-11T22:46:11.027529Z","shell.execute_reply":"2024-04-11T22:46:11.026535Z","shell.execute_reply.started":"2024-04-11T22:46:11.020792Z"},"trusted":true},"outputs":[],"source":["%pip install atomInSmiles\n","%pip install trl\n","\n","import atomInSmiles as AIS\n","from ..AISTokenizer import AISTokenizer\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","import copy\n","import json\n","import os\n","from pathlib import Path\n","from typing import Dict, List, Optional, Sequence, Union\n","from transformers.tokenization_utils import AddedToken, PreTrainedTokenizer\n","import collections\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM , AutoConfig\n","from datasets import load_dataset\n","from datasets import DatasetDict\n","import datasets\n","from transformers import DataCollatorForLanguageModeling \n","from huggingface_hub.hf_api import HfFolder\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# DPO finetuning\n","Here, we finetune our SFT model off of pairings using DPO. We create a PyTorch tokenizer on top of AIS, and load in the pairings we created earlier. We attempt DPO multiple times to find optimized hyperparameters that will help in stable molecular generation (namely, measured by how unique our generated molecule is compared to other outputs and also the inputs given), and output our results when we reach desirable thresholds that measure such qualities."]},{"cell_type":"markdown","metadata":{},"source":["Load in the custom tokenizer with our desired vocab.txt."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:40:18.460093Z","iopub.status.busy":"2024-04-11T22:40:18.459618Z","iopub.status.idle":"2024-04-11T22:40:18.471383Z","shell.execute_reply":"2024-04-11T22:40:18.470506Z","shell.execute_reply.started":"2024-04-11T22:40:18.460055Z"},"trusted":true},"outputs":[],"source":["# reading and tokenizing the vocab file\n","vocabfile = \"/kaggle/input/dpotest/vocab.txt\" \n","context_length = 72\n","tokenizer = AISTokenizer(vocabfile,context_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:40:21.597630Z","iopub.status.busy":"2024-04-11T22:40:21.596953Z","iopub.status.idle":"2024-04-11T22:40:21.685356Z","shell.execute_reply":"2024-04-11T22:40:21.684350Z","shell.execute_reply.started":"2024-04-11T22:40:21.597593Z"},"trusted":true},"outputs":[],"source":["import json\n","# Deserialize our data\n","with open(\"/kaggle/input/dpotest/pairs.json\", \"r\") as file:\n","    data = json.load(file)"]},{"cell_type":"markdown","metadata":{},"source":["Setup DPO pairings from our data loaded in from our pairs file."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:22:12.743645Z","iopub.status.busy":"2024-04-11T22:22:12.743346Z","iopub.status.idle":"2024-04-11T22:23:35.300895Z","shell.execute_reply":"2024-04-11T22:23:35.299943Z","shell.execute_reply.started":"2024-04-11T22:22:12.743618Z"},"trusted":true},"outputs":[],"source":["from datasets import Dataset\n","from typing import Dict\n","import atomInSmiles as AIS\n","\n","# Function to get it in the triplet form for DPO\n","def return_prompt_and_responses(samples) -> Dict[str, list]:\n","    prompt = [\"\"] * len(samples[\"good_docker\"])\n","    chosen = [AIS.encode(sample) for sample in samples[\"good_docker\"]]\n","    rejected = [AIS.encode(sample) for sample in samples[\"bad_docker\"]]\n","\n","    return {\n","        \"prompt\": prompt,\n","        \"chosen\": chosen,\n","        \"rejected\": rejected,\n","    }\n","# Turn our serialized json object into a dataset that we can map to the proper DPO format\n","samples_dict = {\n","    \"good_docker\": [pair[0] for pair in data],\n","    \"bad_docker\": [pair[1] for pair in data],\n","}\n","\n","# Load the dataset\n","dataset = Dataset.from_dict(samples_dict)\n","\n","# Map the function to the dataset\n","mapped_dataset = dataset.map(return_prompt_and_responses, batched=True, remove_columns=list(samples_dict.keys()))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:41:03.756752Z","iopub.status.busy":"2024-04-11T22:41:03.755830Z","iopub.status.idle":"2024-04-11T22:41:03.777628Z","shell.execute_reply":"2024-04-11T22:41:03.776714Z","shell.execute_reply.started":"2024-04-11T22:41:03.756716Z"},"trusted":true},"outputs":[],"source":["# Defining the data collator\n","from trl.trainer.utils import DPODataCollatorWithPadding\n","data_collator = DPODataCollatorWithPadding(\n","                pad_token_id=tokenizer.pad_token_id,\n","                label_pad_token_id=-100,\n","                is_encoder_decoder=False\n","            )\n"]},{"cell_type":"markdown","metadata":{},"source":["Setup utility functions to test whether or not our model is stable enough for generation."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:41:08.063634Z","iopub.status.busy":"2024-04-11T22:41:08.063290Z","iopub.status.idle":"2024-04-11T22:41:08.088004Z","shell.execute_reply":"2024-04-11T22:41:08.087064Z","shell.execute_reply.started":"2024-04-11T22:41:08.063608Z"},"trusted":true},"outputs":[],"source":["# Make a set of every molecule in the dataset to compare novelty against\n","allgenerated = set()\n","for line in data:\n","    allgenerated.add(line[0])\n","    allgenerated.add(line[1])\n","\n","def calc_unique(test_model):\n","    samples = []\n","    novelty = []\n","    for _ in range(250):\n","        # Note: model.generate includes the leading/trailing EOS tokens, so we have to remove them ourselves with [1:-1]\n","        decoded = AIS.decode(tokenizer.decode(test_model.generate(max_new_tokens=72,do_sample=True, temperature=0.5)[0][1:-1]))\n","        samples.append(decoded)\n","        if decoded not in allgenerated:\n","            novelty.append(decoded)\n","    # Calculate samples uniqueness and novelty\n","    unique_elements = set(samples)\n","    novel_elements = set(novelty)\n","    uniqueness_percentage = (len(unique_elements) / len(samples)) * 100\n","    novelty_percentage = (len(novel_elements) / len(samples)) * 100\n","    return uniqueness_percentage, novelty_percentage, unique_elements"]},{"cell_type":"markdown","metadata":{},"source":["## DPO Step\n","Here, we are finally able to start running DPO. We load in our baseline models, and then go over sets of hyperparameters to try various different configurations. If the desired metrics are good enough for generation, we save the hyperparameters, metrics and the unique elements into a file."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T22:46:49.517406Z","iopub.status.busy":"2024-04-11T22:46:49.517016Z","iopub.status.idle":"2024-04-11T22:47:20.825793Z","shell.execute_reply":"2024-04-11T22:47:20.824320Z","shell.execute_reply.started":"2024-04-11T22:46:49.517377Z"},"trusted":true},"outputs":[],"source":["from transformers import Trainer, TrainingArguments\n","from trl import DPOTrainer\n","from transformers.utils import logging\n","logging.set_verbosity_error()\n","\n","# hyperparameters to sweep over\n","epochs = [1, 2, 3]\n","betas = [0.1, 0.3, 0.5]\n","lrs = [1e-5, 3e-5, 5e-5, 1e-4]\n","\n","# sweeping over hyperparameters\n","for epoch in epochs:\n","    for beta in betas:\n","        for lr in lrs:\n","            # loading reference model\n","            model = AutoModelForCausalLM.from_pretrained(\n","                \"victornica/AIS_3\", # location of saved SFT model\n","            )\n","            model_ref = AutoModelForCausalLM.from_pretrained(\n","                \"victornica/AIS_3\", # location of saved SFT model\n","            )\n","            # setting arguments\n","            args = TrainingArguments(\n","                output_dir=\"/kaggle/working/\",\n","                per_device_train_batch_size=128,\n","                per_device_eval_batch_size=128,\n","                num_train_epochs=epoch,\n","                weight_decay=0.1,\n","                learning_rate=lr,\n","                lr_scheduler_type=\"linear\",\n","                report_to=\"none\"\n","            )\n","            # initializing trainer\n","            dpo_trainer = DPOTrainer(\n","                model,\n","                model_ref,\n","                args=args,\n","                beta=beta,\n","                train_dataset=mapped_dataset, \n","                tokenizer=tokenizer,\n","                is_encoder_decoder=False,\n","            )\n","            \n","            # training model\n","            dpo_trainer.train()\n","\n","            # looking at how many unique and novel elements were generated and \n","            # what the unique elements were\n","            uniqueness, novelty, unique_elems = calc_unique(model)\n","            # only track them if 98% of generated elements were unique\n","            if uniqueness >= 98:\n","                file = open(f\"{epoch}-{beta}-{lr}-{uniqueness}-{novelty}.txt\", \"w\")\n","                file.write(f\"{unique_elems}\")\n","                file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T03:04:52.999831Z","iopub.status.busy":"2024-04-06T03:04:52.999418Z","iopub.status.idle":"2024-04-06T03:04:55.459036Z","shell.execute_reply":"2024-04-06T03:04:55.457912Z","shell.execute_reply.started":"2024-04-06T03:04:52.999794Z"},"trusted":true},"outputs":[],"source":["# Sanity check to see if training looked ok\n","for _ in range(5):\n","    # Note: model.generate includes the leading/trailing EOS tokens, so we have to remove them ourselves with [1:-1]\n","    print(AIS.decode(tokenizer.decode(model.generate(max_new_tokens=72,do_sample=True)[0][1:-1])))"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4740955,"sourceId":8041361,"sourceType":"datasetVersion"},{"datasetId":4779371,"sourceId":8149952,"sourceType":"datasetVersion"}],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
